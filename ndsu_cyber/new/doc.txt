Documentation for what I've been doing


before we can draw conclusions from whether certain lighting or positions can
be exploited by attackers to fool a recognition system, there are some settings
that need to be tuned such that the recognition system is performing its best
during the important testing.

to do this, i took note of the settings that were program-specific:
    casc (file used for the haar cascade classifier)
    sf (scale factor)
    mn (minimum neighbors)
    res (height of the resolution to resize to)

some constants were also used:
    all of the images in the dataset are presented in JPG with a ratio w/h of
    1:5. a res value of 480 represents the resolution (720 x 480)

after noting these, i collected training data from the program using many
variations of the program's variables:
    casc: lbph_frontal.xml, and haar_default.xml
    sf: 1.01, 1.05, 1.1, 1.2, 1.3, and 1.5
    mn: 1, 3, 5, 7, and 10
    res: 150, 480, 960, 1920, and 3456

each variation had its labels and training data saved in the folder in which
it was used to create images.

running the training took a long time (around 29 hours) on a fast computer.

after using all possible variations between the selected option values, i had
to write a parsing script that would let me easily see differences with stats
between the different training settings.

choosing the best training data to test with was difficult. i had the ability
to sort all resulting tests by number of faces detected, number of images
skipped (due to no face being detected), amongst other things, like total
runtime.

i decided that the most important value to look at was the number of faces
detected, as too high of a number would greatly decrease recognition accuracy.

i also discovered that ranking the tests purely by numbers was not enough.
if exactly the same number of faces were detected as how many there actually
was, there is no way to tell if the face is a legitimate face or not without
human review (or experimental neural networking).

to decide which tests had the best results, i first sorted the tests by
number of faces detected and then manually reviewed each set of images from
each test. i only picked the best 5 from a set of 14, as more than 5 would
take an extremely long time to finish.

i also collected general percentage values of detected faces for each setting.
with this knowledge and the 5 tests that i chose, i was ready to start
messing around with the testing program's settings.

for each of the training tests that i selected (5 total), i tested the same
variety of program settings on the test script. In theory, accuracy should
always be 100% if the images used for training are the same ones used for
testing. However, this is not the case when there are differences in settings
between what the training set was created with and what is used in the testing
script. For example, if the training set had the following settings:

SF: 1.1
MN: 3
H: 150

but was used with a testing script with the following settings:
SF: 1.5
MN: 3
H: 480

There are going to be some inaccuracies. This can be a GOOD thing, as training
data was created using EVERY detected "Face", even if the detected "Face"
was not a face at all, which means, if the training program detects faces that
really aren't faces, then you're going to see 100% recognition accuracy using
the same testing settings (which can be bad since it recognized various
rectangles across the screen that aren't faces as faces). Having a little bit of
variation can act as a "Filter" for negating those false face detections.

Let's say that when the program detects a face that isn't a real face, the face
that is detected
is called a "dummy face". If there are many dummy faces in the training data,
recognition accuracy is going to be poor since the REAL faces detected for
one subject are averaged with dummy faces, making it hard to recognize one
subject's face over another. 

however, if the testing program is using different settings, even though that
some of the training data has dummy faces present, the testing program can make
a more accurate prediction from using more strict face detection settings.








